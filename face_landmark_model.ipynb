{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_landmark_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRcCQfho4pow",
        "outputId": "a0445cf8-4359-4eb1-91e5-7e3add4fa33b"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'ajay25212'\n",
        "os.environ['KAGGLE_KEY'] = '35248e97e2b7dea00d6e61dcfef59c39'\n",
        "\n",
        "\n",
        "! kaggle competitions download -c facial-keypoints-detection\n",
        "\n",
        "! unzip test.zip\n",
        "\n",
        "! unzip training.zip\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading SampleSubmission.csv to /content\n",
            "  0% 0.00/201k [00:00<?, ?B/s]\n",
            "100% 201k/201k [00:00<00:00, 30.5MB/s]\n",
            "Downloading IdLookupTable.csv to /content\n",
            "  0% 0.00/843k [00:00<?, ?B/s]\n",
            "100% 843k/843k [00:00<00:00, 50.2MB/s]\n",
            "Downloading test.zip to /content\n",
            " 81% 13.0M/16.0M [00:00<00:00, 62.3MB/s]\n",
            "100% 16.0M/16.0M [00:00<00:00, 63.4MB/s]\n",
            "Downloading training.zip to /content\n",
            " 78% 47.0M/60.1M [00:00<00:00, 49.8MB/s]\n",
            "100% 60.1M/60.1M [00:00<00:00, 94.7MB/s]\n",
            "Archive:  test.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  training.zip\n",
            "  inflating: training.csv            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGtc-bhe4st3"
      },
      "source": [
        "# Import required libraries for this section\n",
        "\n",
        "# magical function which is used to display visualization in notebook \n",
        "%matplotlib inline\n",
        "\n",
        "# numpy - used for manipulating array/matrix \n",
        "import numpy as np\n",
        "\n",
        "# matplotlib.pyplot - used for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# math - used for basic math operation\n",
        "# import math\n",
        "\n",
        "# OpenCV library for computer vision - image processing\n",
        "import cv2                     \n",
        "\n",
        "# PIL - Python Imaging Library\n",
        "# from PIL import Image\n",
        "\n",
        "# time - used for time related operation\n",
        "# import time \n",
        "\n",
        "# alternative for cv2.imshow, since colab block cv2.imshow functionality due to kernel kill\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# pandas - for data accessing and manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# shuffle - for shuffling the datas\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Sequential - A base layer where the extra layer of the network can be added\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Convolution2D -layer used to perform the convolution operationel \n",
        "from keras.layers import Convolution2D\n",
        "\n",
        "# MaxPooling2D - layer used to perform the MaxPooling operation\n",
        "from keras.layers import MaxPooling2D\n",
        "\n",
        "# Dropout - Layer used to drop the ddata which can lea to over fitting of the mod\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# Flatten - layer which is used to Flatten a 2D array value into 1D array/features values\n",
        "from keras.layers import Flatten\n",
        "\n",
        "# Dense - Layer which is used to make a fully connected layer\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Adam - Optimiser which is used to optimise the model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# ModelCheckpoint - Chekpoint where the model is saved based on best values\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "\n",
        "# \n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmLizAYh44NZ"
      },
      "source": [
        "def load_data(test=False):\n",
        "    \"\"\"\n",
        "    Loads data from FTEST if *test* is True, otherwise from FTRAIN.\n",
        "    Important that the files are in a `data` directory\n",
        "    \"\"\"  \n",
        "\n",
        "    # defining the test and training dataset path\n",
        "    FTRAIN = 'data/training.csv'\n",
        "    # print(\"\\nFTRAIN :\\n\",FTRAIN)-> data/training.csv\n",
        "    \n",
        "    FTEST = 'data/test.csv'\n",
        "    # print(\"\\nFTEST :\\n\",FTEST)-> data/test.csv\n",
        "    \n",
        "    fname = FTEST if test else FTRAIN\n",
        "    # print(fname) data/training.csv and data/test.csv\n",
        "\n",
        "    # reading the csv file\n",
        "    # load dataframes\n",
        "    df = pd.read_csv(os.path.expanduser(fname))\n",
        "    \n",
        "    # print(df.shape)  # (1783, 2)\n",
        "\n",
        "    # The Image column has pixel values separated by space; \n",
        "    # convert the values to numpy arrays:\n",
        "    # print(df['Image']) -> 238 , Name: Image, Length: 7049, dtype: object\n",
        "    # fromstring - function is used to create a new 1-D array initialized from raw binary or text data in a string\n",
        "    df['Image'] = df['Image'].apply(lambda img: np.fromstring(img, sep=' '))\n",
        "    # print(df['Image']) -> [238.0] , Name: Image, Length: 7049, dtype: object\n",
        "    \n",
        "    # drop all rows that have missing values in them\n",
        "    df = df.dropna() \n",
        "    \n",
        "    # scale pixel values to [0, 1]\n",
        "    # np.vstack -  used to stack the sequence of input arrays vertically to make a single array\n",
        "    x = np.vstack(df['Image'].values) / 255.\n",
        "    # print(x)  -> [0.93333333]\n",
        "    # print(x.dtype) -> float64\n",
        "\n",
        "    # changing the datatype\n",
        "    x = x.astype(np.float32)\n",
        "    # print(x) - >[0.93333334]\n",
        "    # print(x.dtype) -> float32\n",
        "    \n",
        "    # changing the shape\n",
        "    x = x.reshape(-1, 96, 96, 1) \n",
        "    # print(x.shape)  -> return each images as 96 x 96 x 1\n",
        "\n",
        "    # only FTRAIN has target columns\n",
        "\n",
        "    if not test:  \n",
        "       \n",
        "        # post processing to make the 15 landmarks into 5 landmarks\n",
        "        df.drop(['left_eye_inner_corner_x',\n",
        "                 'left_eye_inner_corner_y',\n",
        "                 'left_eye_outer_corner_x',\n",
        "                 'left_eye_outer_corner_y',\n",
        "                 'right_eye_inner_corner_x',\n",
        "                 'right_eye_inner_corner_y',\n",
        "                 'right_eye_outer_corner_x',\n",
        "                 'right_eye_outer_corner_y',\n",
        "                 'left_eyebrow_inner_end_x',\n",
        "                 'left_eyebrow_inner_end_y',\n",
        "                 'left_eyebrow_outer_end_x',\n",
        "                 'left_eyebrow_outer_end_y',\n",
        "                 'right_eyebrow_inner_end_x',\n",
        "                 'right_eyebrow_inner_end_y',\n",
        "                 'right_eyebrow_outer_end_x',\n",
        "                 'right_eyebrow_outer_end_y',\n",
        "                 'mouth_center_top_lip_x',\n",
        "                 'mouth_center_top_lip_y',\n",
        "                 'mouth_center_bottom_lip_x',\n",
        "                 'mouth_center_bottom_lip_y' ], axis = 1, inplace = True)\n",
        "\n",
        "        \n",
        "        # getting the target data and converting it into array\n",
        "        y = df[df.columns[:-1]].values\n",
        "        # print(y) ->[66.03356391 39.00227368 30.22700752 ... 79.97016541 28.61449624 77.38899248]\n",
        "        # print(y.shape) -> (2140, 10)\n",
        "        \n",
        "        # scale / normalizing target coordinates to [-1, 1]\n",
        "        y = (y - 48) / 48\n",
        "        # print(y)  ->[ 0.37569925 -0.18745263 -0.37027068 ...  0.66604511 -0.40386466 0.61227068]\n",
        "        # print(y.shape) # -> (2140, 10)\n",
        "        \n",
        "        # shuffle train data\n",
        "        x, y = shuffle(x, y, random_state=42)\n",
        "        # print(x,y)\n",
        "\n",
        "        # changing the datatype\n",
        "        y = y.astype(np.float32)\n",
        "        # print(y) #- >[ 0.3816111  -0.21757638 -0.40208334 ...  0.5116389  -0.38531944  0.5158264 ]\n",
        "        # print(y.dtype) # -> float32\n",
        "    \n",
        "    else:\n",
        "        \n",
        "        y = None\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U3pLQdW7_K5",
        "outputId": "0f735599-8d37-4426-dc8c-a5681ede8f37"
      },
      "source": [
        "\n",
        "\n",
        "# Load training set\n",
        "x_train, y_train = load_data()\n",
        "# print(x_train) -> [0.79607844], value in the form of numpy array\n",
        "# print(\"x_train.shape ==\",x_train.shape) # (2140, 96, 96, 1)\n",
        "# print(y_train) ->[ 0.3816111  -0.21757638 -0.40208334 ...  0.5116389  -0.38531944, 0.5158264 ] ,value in the form of numpy array\n",
        "# print(\"y_train.shape ==\", y_train.shape) # (2140,10)\n",
        "    \n",
        "# Load testing set\n",
        "x_test, _ = load_data(test=True)\n",
        "# print(\"x_test.shape ==\",x_test.shape) # (1783, 96, 96, 1)\n",
        "# print(x_test) -> [0.7137255 ], value in the form of numpy array\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.3816111  -0.21757638 -0.40208334 ...  0.5116389  -0.38531944\n",
            "   0.5158264 ]\n",
            " [ 0.4330242  -0.21624877 -0.3466828  ...  0.3931978  -0.4643302\n",
            "   0.31000873]\n",
            " [ 0.3582826  -0.26738405 -0.388      ...  0.56476086 -0.3285652\n",
            "   0.5713623 ]\n",
            " ...\n",
            " [ 0.40102914 -0.25295144 -0.3799806  ...  0.53673786 -0.25848544\n",
            "   0.51937866]\n",
            " [ 0.45343795 -0.1929708  -0.4018394  ...  0.7437591  -0.33889782\n",
            "   0.7437591 ]\n",
            " [ 0.45054716 -0.32877925 -0.4011132  ...  0.53973585 -0.25777358\n",
            "   0.4975849 ]]\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D1Z2Yea8P2X",
        "outputId": "d66c554a-b2c5-4d02-de88-d1f81726f9f0"
      },
      "source": [
        "# Import deep learning resources from Keras\n",
        "# model accept 96x96 pixel graysale images in\n",
        "# It should have a fully-connected output layer with 10 values (2 for each facial keypoint)\n",
        "\n",
        "# A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
        "model = Sequential()\n",
        "\n",
        "# Convolution2D - convolution layer\n",
        "# 64 - no . of filters used\n",
        "# 3, 3, - size of the filter/ kernel\n",
        "# input shape - input of the model\n",
        "# activation - non linear function used for checking the active status of the neuron\n",
        "model.add(Convolution2D(64, 3, 3, input_shape=(x_train.shape[1:])))\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "\n",
        "# MaxPooling2D - max polling used to get the maxmium features out\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "# Flattern - Converting the 2D array values into 1D flattern data\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense - Dense layer with 128 features\n",
        "model.add(Dense(128, activation='tanh'))\n",
        "\n",
        "# Dropout - Dropout the data to make sure the moel doesnt over fit\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Dense - Dense layer with 30 features\n",
        "model.add(Dense(10, activation='tanh'))\n",
        "\n",
        "\n",
        "# Summarize the model\n",
        "model.summary()\n",
        "\n",
        "# Total params: 246,366\n",
        "# Trainable params: 246,366"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbbIk70V9Yz6",
        "outputId": "b6c7c84f-1d48-4c08-9ea6-b6d1810ac8a9"
      },
      "source": [
        "# Compiling the model\n",
        "# loss = used to compute the quantity that a model should seek to minimize during training.\n",
        "# landmark detection is a Regression losses problem thus using mean_squared_error\n",
        "# mean_squared_error - Computes the mean of squares of errors between labels and predictions.\n",
        "# optimizer - is used to optimize the moddel for the loss value to achive the global minima\n",
        "# adam - adam is a optimiser function which is stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Save the model as model.h5\n",
        "# ModelCheckpoint : used in conjunction with training using model.fit() to save a model or weights (in a checkpoint file) at some interval\n",
        "# filepath: string or PathLike, path to save the model file\n",
        "# save_best_only=True - only saves when the model is considered the \"best\"\n",
        "# save_weigths_only=True - only saves when the model is considered the \"best\"\n",
        "# verbose: verbosity mode, 0 or 1.\n",
        "# verbose = 1, which includes both progress bar and one line per epoch. verbose = 0, means silent\n",
        "# verbose - helps to detect overfitting which occurs if your acc keeps improving while your val_acc gets worse.\n",
        "checkpointer = ModelCheckpoint(filepath='model/model.h5',\n",
        "                               verbose=1,\n",
        "                               save_best_only=True,\n",
        "                               save_weights_only=True)\n",
        "\n",
        "# training the model\n",
        "# x_train, y_train -input datas\n",
        "# batch_size - no of batches to be performed\n",
        "# epochs - no of epochs to be done for all the batches\n",
        "# validation_split - spliting the data for validation, which can be used to validate the model\n",
        "# callbacks -  used to monitor your metrics \n",
        "# verbose: verbosity mode, 0 or 1.\n",
        "# verbose = 1, which includes both progress bar and one line per epoch. verbose = 0, means silent\n",
        "# verbose - helps to detect overfitting which occurs if your acc keeps improving while your val_acc gets worse.\n",
        "# shuffle - used to shuffle the data for random access\n",
        "hist = model.fit(x_train, y_train,\n",
        "                 batch_size=64,\n",
        "                 epochs=30,\n",
        "                 validation_split=0.2,\n",
        "                 callbacks=[checkpointer], \n",
        "                 verbose=1,\n",
        "                 shuffle=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "27/27 [==============================] - 3s 79ms/step - loss: 0.0193 - val_loss: 0.0060\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00601, saving model to model/model.h5\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.0086 - val_loss: 0.0048\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.00601 to 0.00484, saving model to model/model.h5\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.0067 - val_loss: 0.0040\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00484 to 0.00396, saving model to model/model.h5\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 2s 68ms/step - loss: 0.0059 - val_loss: 0.0035\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00396 to 0.00349, saving model to model/model.h5\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.0052 - val_loss: 0.0034\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00349 to 0.00336, saving model to model/model.h5\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0046 - val_loss: 0.0032\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00336 to 0.00324, saving model to model/model.h5\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.0043 - val_loss: 0.0035\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00324\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0043 - val_loss: 0.0036\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00324\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0038 - val_loss: 0.0029\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00324 to 0.00294, saving model to model/model.h5\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0035 - val_loss: 0.0030\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00294\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.0032 - val_loss: 0.0029\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00294 to 0.00285, saving model to model/model.h5\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 2s 71ms/step - loss: 0.0031 - val_loss: 0.0028\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00285 to 0.00278, saving model to model/model.h5\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 2s 72ms/step - loss: 0.0031 - val_loss: 0.0029\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00278\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 2s 71ms/step - loss: 0.0029 - val_loss: 0.0030\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00278\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 2s 71ms/step - loss: 0.0028 - val_loss: 0.0029\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00278\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0027 - val_loss: 0.0028\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00278\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0026 - val_loss: 0.0028\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00278\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0025 - val_loss: 0.0028\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00278 to 0.00276, saving model to model/model.h5\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00276\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0022 - val_loss: 0.0031\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00276\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00276\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00276\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00276\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00276\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 2s 71ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00276 to 0.00274, saving model to model/model.h5\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 2s 72ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00274\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00274\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 2s 69ms/step - loss: 0.0018 - val_loss: 0.0030\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00274\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00274\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 2s 70ms/step - loss: 0.0017 - val_loss: 0.0029\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo0-Uyd4-YLP",
        "outputId": "5a1a0080-5672-4fd3-e32b-4c94b78ee07f"
      },
      "source": [
        "tf.saved_model.save(model,'model')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}